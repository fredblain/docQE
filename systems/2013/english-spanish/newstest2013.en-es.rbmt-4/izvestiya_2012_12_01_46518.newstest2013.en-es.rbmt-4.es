"De momento, la mente no se puede engañar demasiado bien"
Entre admiradores de tecnología modernos un tema popular se aumenta realidad, últimamente vista ante todo a través del prisma de gafas especiales.
Al principio, un modelo funcional era enseñado por Google en el verano, en su conferencia anual. Entonces, en noviembre, se anunciaba que Microsoft archivaba una solicitud de patente demasiado.
Sin embargo, según la conversación con el líder del grupo de interactivo 3 D tecnologías en el laboratorio de Cambridge de Microsoft, Shahram Izadi, las gafas son una cosa del pasado para científicos en esta compañía.
Se dibujan por la perspectiva de manipular objetos virtuales en el aire con pelotas a mano, creando espacios libres virtuales.
- Por favor díganos que, en plazos sencillos, sobre el trabajo su grupo de investigación hace.
- Trabajamos en la interacción de gente con máquinas, al mismo tiempo intentando expandir los límites de esta interacción.
Mientras en general se sigue con gente trabajando con píxeles en una pantalla plana y a veces señalando dedos en ellos.
Queremos mirar 5-10 años el futuro y predecir cambios cardinales en esta interacción.
Por ejemplo, los sensores de Xbox y Kinect son un paso hacia adelante. Casi ningún Xbox se vende sin Kinect hoy, porque a todo el mundo le gusta el control por gestos.
- ¿Qué más nos espera en el futuro?
- A pesar del hecho de que Kinect cambiaba la interacción al nivel físico, mucho todavía ocurre en una pantalla plana, a veces en 3 D.
La entrada de información ha mejorado (el sistema recibe más datos), pero la salida todavía tiene que mejorar.
Estamos intentando cambiar esto, trabajando en sistemas de muestra verdaderamente tridimensionales basados en diversas tecnologías, incluyendo tecnologías de proyección.
Tenemos que alquilar el mundo de ordenador en nuestro mundo físico, hacerlo más tangible.
Pero para esto, tenemos que identificar tanto el usuario como el espacio alrededor de él.
Entonces podremos completar el mundo real con objetos virtuales en una forma mucho más conveniente.
¡Sobre todo, deshágase de estos cascos de realidad virtual tontos!
- ¿Qué piensa en control de voz?
¿Es una cosa popular, pero es sobreestimaba?
- Claramente no se puede llamar un cure-for-all - hay una cuestión de intimidad, porque no queremos siempre dejar los otros saber de nuestras acciones y las intenciones.
En realidad, todos los tipos de interacción con ordenadores son buenos, menos cada uno en su propia hornacina.
Por ejemplo, teníamos un proyecto a dispositivos de mando en lugares públicos, en los cuales pensábamos en movimientos, movimientos no amplios, pero pequeños, reservados.
Los movimientos no eran registrados por una cámara, sino por un brazalete de mano que determinaba el movimiento de huesos y músculos.
Es grande ahora mismo, pero en teoría se puede reducir al tamaño de un reloj de mano.
En general, el futuro está en el control mixto, p.ej. voz de + de movimiento.
- ¿Qué quiere?
- ¿Por ejemplo, cómo me pediría que le dé esta botella de agua?
Hablará y se verá al mismo tiempo.
- Normalmente sólo digo.
- Oh, eso será muy difícil de detectar.
- ¿Así quiere hacer a los usuarios adaptarse a qué la máquina puede o no puede hacer en aquel momento?
- No necesariamente, pero es una aproximación mutua.
Pienso en el futuro cercano, trabajaremos principalmente para desarrollar sensores nuevos que permitirán más determinación precisa de la reacción de una persona.
Esto podría ser, p.ej. sensores de láser. Tienen una resolución de profundidad decente, que es muy importante.
- ¿Si hablamos de su trabajo con sensores de Xbox Kinect, qué son sus quejas sobre cámaras modernas?
¿No lo bastante resolución, profundidad o algo más?
- En general, la generación actual es en qué nos podemos basar al trabajar en reconocimiento tridimensional.
Por supuesto, sería bueno tener píxeles de ocho megas con 1000 k/s velocidad.
No es sólo los mega píxeles, sin embargo, sólo la calidad de la matriz y la profundidad.
Del último punto de vista, todas las tecnologías actuales no son lo bastante buenas para nosotros - esto añade trabajo a los diseñadores de algoritmo.
Así es importante acordarse sobre la resolución sobre el X, Y, pero también el Eje Z.
La velocidad, la cantidad de imágenes por segundo, es también muy importante.
Los movimientos humanos son relativamente dinámicos, y el 30 k/s actual es realmente no bastante, especialmente para gestos.
Steven Bathiche de nuestro laboratorio de Redmond creaba un poco sensor con una demora de procesamiento regulada de 1 a 100 ms, mientras los sensores en serie modernos están más próximos al último indicador (60-100).
No todo el mundo entiende cómo afecta esto la interacción entre hombre y máquina.
En mi trabajo, sería muy útil tener un dispositivo que no exige tocar y tendría más imágenes por segundo.
- ¿La cantidad de cámaras tiene que ser aumentada?
- En Kinect hay tres cámaras ahora, uno del cual es realmente un emisor infrarrojo y el segundo uno, el receptor de la señal.
El tercero es realmente un sensor regular de gama visible.
No se aplica para determinar la profundidad del objeto.
Potencialmente, una gran cantidad de cámaras podrían resolver el problema...
O hágalo peor, aumentando el volumen necesario de cálculos.
Sería bueno de crear una cosa análoga flexible Kinect, jugar con la flexión de disposición de cámara y ver cómo ayudará esto en la determinación tridimensional de la posición.
- Hasta donde me acuerdo, Microsoft no presentaba sus gafas al público, a diferencia de Google.
¿No cree que esto es una de las plataformas más prometedoras del punto de vista el uso diario de tecnologías de realidad ampliadas?
- Naturalmente no es muy conveniente dar vueltas con un smartphone en sus manos elevadas todo el tiempo, pero creo que la opción más tranquila sería realidad ampliada "transicional", donde se podría mover de gafas a smartphone, muestra de proyección, y en todas partes basaba en una plataforma de nube.
Las gafas son un dispositivo muy personal, ése es su fuerza (las cosas particulares son vistas solamente por Usted) y, al mismo tiempo, su debilidad - la realidad ampliada basada en gafas no le permitirá trabajar en objetos virtuales juntamente con otra gente.
- Déjenos imaginar durante un minuto que la manipulación de objetos holográficos virtuales en el aire está disponible no solamente a Tony Stark de Ironman, sino para una persona regular.
Hay un problema con esta idea que los críticos a menudo señalan: ¡ninguna realimentación táctil!
¡Las manos no sienten nada!
¿Qué respuestas prepara su grupo a este reto?
- En mis conferencias a menudo digo que aumentaba realidad es el séptimo intento consecutivo de la interacción entre hombre y máquina.
Creo que la octava parte será probablemente la adición de sensaciones táctiles.
Para ahora, uno de los trucos interesantes es utilizar la segunda mano como una clase de matriz para la imagen.
¡Es bueno para empuje que se registran!
Pero hay tecnologías que se esperan realmente que den estas "imágenes en el aire" un sentido de tangibilidad, por ejemplo, la interferencia de varias rayas de ultrasonido a las cuales se apunta en un punto específico donde el dedo se localiza da una sensación, pero muy débil ahora mismo, como si alguien soplara en su yema.
Hay también brazaletes de muñeca que afectan a los finales nerviosos en dedos, lo cual es también un área prometedora.
- ¿Ha intentado engañar la mente?
¿Obligar a creer que siente algo que debería estar sintiendo cuándo ve algo?
- Esto es una buena idea y no hemos probado esto todavía.
Oculta un reto que no se resolverá así rápidamente - cómo imponer a una persona, que está físicamente en un espacio muy limitado para creer que está andando a lo largo de un espacio abierto, casi ilimitado; estamos trabajando en el concepto de ruedas de molino (no en todo como en clubes), plataformas que se mueven, y globos gigantescos.
Hasta aquí engañando la mente tiene habido limitado éxito, hay trabajar para que vengan muchos años.
Eso es qué hace trabajando en realidad virtual tan interesante para investigadores - muchas cosas son en sus principios very.
