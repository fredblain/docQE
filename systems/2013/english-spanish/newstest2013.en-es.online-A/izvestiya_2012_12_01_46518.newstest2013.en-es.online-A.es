"En este momento, la mente no puede ser engañada muy bien"
Entre los fanáticos de la tecnología moderna, un tema popular es realidad aumentada, visto últimamente principalmente a través del prisma de gafas especiales.
Al principio, un modelo funcional fue demostrado por Google en el verano, en su conferencia anual. Luego, en noviembre, fue anunciado que Microsoft presentó también una solicitud de patente.
Sin embargo, según la conversación con el líder del grupo de tecnologías interactivas 3D en el laboratorio de Cambridge de Microsoft, Shahram Izadi, gafas son una cosa del pasado para los científicos en esta empresa.
Ellos son atraídos por la posibilidad de manipular objetos virtuales en el aire con las manos desnudas, creando espacios virtuales.
-Por favor díganos, en términos simples, sobre el trabajo que hace el grupo de investigación.
-Trabajamos en la interacción de personas con máquinas, al mismo tiempo tratando de ampliar los límites de esta interacción.
Mientras que la gente en general se pegan en el trabajo con píxeles en una pantalla plana y a veces ellos señalando los dedos.
Queremos ver a 5-10 años hacia el futuro y predecir cambios cardinales en esta interacción.
Por ejemplo, sensores de Xbox y Kinect son un paso adelante. Casi no Xbox se vende sin Kinect hoy, porque todo el mundo le gusta el control por gestos.
-¿Qué nos espera en el futuro?
-A pesar del hecho de que Kinect cambió la interacción a nivel físico, mucho todavía se produce en una pantalla plana, a veces en 3D.
Entrada de información ha mejorado (el sistema recibe más datos), pero la salida queda mejor.
Intentamos cambiar esto, trabajando en sistemas de visualización tridimensional verdaderamente basados en diversas tecnologías, incluidas las tecnologías de proyección.
Tenemos que dejar que el mundo de la informática en nuestro mundo físico, hacer más tangible.
Pero para ello, necesitamos identificar el usuario y el espacio que le rodea.
Entonces seremos capaces de suplir el mundo real con objetos virtuales en una forma mucho más conveniente.
Sobre todo, deshacerse de estos cascos de realidad virtual estúpido!
-¿Qué opinas sobre control de voz?
¿Es algo popular, pero se sobreestima?
-Que claramente no puede llamarse una cura para todos - hay una cuestión de privacidad, porque no siempre queremos que los demás sepan acerca de nuestras acciones e intenciones.
En realidad, todos los tipos de interacción con las computadoras son buenos, pero cada uno en su propio nicho.
Por ejemplo, tuvimos un proyecto para dispositivos de control en lugares públicos, en el que pensamos en movimientos, movimientos no amplio, pero los pequeños, reservados.
No se registraron movimientos por una cámara, sino por un brazalete de mano que determina el movimiento de los huesos y músculos.
Ahora mismo es grande, pero en teoría puede ser reducido al tamaño de un reloj de mano.
En general, el futuro está en el control mixto, por ejemplo, movimiento + voz.
-¿Qué quieres decir?
¿-Por ejemplo, cómo le pides que te dé esta botella de agua?
Se hablar y mostrar al mismo tiempo.
-Generalmente solo digo.
-Oh, será muy difícil de detectar.
¿-Por lo que usted quiere hacer los usuarios adaptarán a lo que la máquina puede o no puede hacer en ese momento?
-No necesariamente, pero es una aproximación mutua.
Creo que en un futuro cercano, trabajamos principalmente en el desarrollo de nuevos sensores que permitirán la determinación más precisa de la reacción de una persona.
Esto podría ser, por ejemplo sensores láser. Tienen una resolución decente de profundidad, que es muy importante.
-Si hablamos de su trabajo con sensores de Xbox Kinect, ¿cuáles son tus quejas sobre cámaras modernas?
¿No hay suficiente resolución, profundidad o algo más?
-En general, la generación actual es lo que nos podemos basamos en trabajar en reconocimiento tridimensional.
Por supuesto, sería bueno tener ocho megapíxeles con 1000 k/s de velocidad.
No es sólo los mega píxeles, aunque, pero la calidad de la matriz y la profundidad.
Desde el último punto de vista, todas las tecnologías actuales no son lo suficientemente buenas como para nosotros - esto añade trabajo a los diseñadores del algoritmo.
Por lo que es importante recordar sobre la resolución en el X, Y, sino también en el eje Z.
Velocidad, el número de imágenes por segundo, también es muy importante.
Los movimientos son relativamente dinámicos, y el actual 30 k/s realmente no es suficiente, especialmente para los gestos.
Steven Bathiche de nuestro laboratorio de Redmond creado un sensor táctil con un retraso de procesamiento regulado de 1 a 100 ms, mientras que los sensores serie modernos están más cercanos del último indicador (60-100).
No todo el mundo entiende cómo esto afecta a la interacción entre hombre y máquina.
En mi trabajo, sería muy útil contar con un dispositivo que no es necesario tocar y tendría más imágenes por segundo.
-¿El número de cámaras debe aumentarse?
-En Kinect hay tres cámaras, una de ellas es realmente un emisor de rayos infrarrojos y la segunda, el receptor de la señal.
La tercera es realmente un sensor regular de la gama visible.
No se aplica para determinar la profundidad del objeto.
Potencialmente, un gran número de cámaras podría solucionar el problema...
O hacerlo peor, incrementando el volumen requerido de cálculos.
Sería bueno crear un análogo flexible Kinect, jugar con la flexión de la disposición de la cámara y ver cómo esto le ayudará a determinar la posición tridimensional.
-Lo que recuerdo, Microsoft no mostró sus gafas al público, a diferencia de Google.
¿No crees que esto es una de las plataformas más prometedores desde el punto de vista el uso diario de las tecnologías de realidad aumentada?
-Ciertamente no es muy conveniente para andar por ahí con un teléfono inteligente en sus manos levantados todo el tiempo, pero creo que la mejor opción sería realidad aumentada "transitorio", donde podría cambiar de gafas para un teléfono inteligente, pantalla de proyección y en cualquier otro sitio basado en una plataforma en la nube.
Gafas están un dispositivo muy personal, que es su fuerza (las cosas privadas se ven sólo por usted) y, al mismo tiempo, su debilidad - realidad aumentada basada en vasos no permitirá trabajar sobre objetos virtuales junto con otras personas.
-Imaginemos un minuto que la manipulación de objetos virtuales holográficos en el aire está disponible no sólo a Tony Stark de Ironman, sino a una persona normal.
Hay un problema con esta idea de que los críticos a menudo señalan que: no hay retroalimentación táctil!
Las manos no sienten nada!
¿Qué respuestas se prepara tu grupo a este desafío?
-En mis conferencias a menudo dicen que la realidad aumentada es el séptimo intento consecutivo en la interacción entre hombre y máquina.
Creo que el octavo será probablemente la adición de sensaciones táctiles.
Por ahora, uno de los trucos interesantes es utilizar la segunda mano como una especie de matriz para la imagen.
Es muy bueno registrar empuja!
Pero hay tecnologías que realmente están dirigidas a dar a estas "imágenes en el aire" una sensación de tangibilidad, por ejemplo, la interferencia de varios rayos de ultrasonidos dirigidos en un punto específico donde se encuentra el dedo da una sensación, pero muy débil ahora, como si alguien sopló en la punta del dedo.
También hay pulseras de muñeca que afectan las terminaciones nerviosas en los dedos, que también es un área prometedora.
-¿Ha intentado engañar a la mente?
¿Para forzarlo a pensar que se siente algo que debe estar sintiendo cuando ve algo?
-Esto es una buena idea y no hemos probado esto todavía.
Oculta un desafío que no se resolverá tan rápidamente - cómo para forzar a una persona, que está físicamente en un espacio muy limitado para creer que él está caminando a lo largo de un espacio abierto, casi ilimitado; Estamos trabajando en el concepto de cintas de correr (no en todos como en clubes), plataformas y globos gigantes.
Hasta ahora engañar la mente ha tenido limitado éxito, hay trabajo por muchos años por venir.
Eso es lo que hace el trabajo en realidad virtual tan atractivo para los investigadores - muchas cosas en sus inicios.
