"The brain is so far only moderately on lists."
Supporters of modern technology in the popular theme of augmented reality is perceived in recent times, usually through the lens of a special glasses.
Google first presented in the summer at its annual conference a working model in November was then known, that Microsoft had filed for a patent.
In conversation with the head of the group for interactive 3D technologies in the Microsoft laboratory in Cambridge Shahram Izadi, however, it is clear that the glasses for the scientists of the company was only a transit station.
It irritates the ability to manipulate virtual objects in the air with their bare hands and to create virtual open spaces.
- you briefly describe what your research group operates.
We deal with the interaction between man and machine, however, want to extend the boundaries of this interaction.
So far, the human race is largely stuck in the phase, which works with pixels on flat screens, which are sometimes affected.
However, we want to look ahead 5-10 years, and the radical changes this interaction foresee.
For example, the Xbox console and the sensors take a step forward, and today is no longer sold without taking Xbox, since all motion control.
- What awaits us in the future?
- Although taking brought the interaction on a physical level, much is still on the flat screen, sometimes in 3D.
The input of information (the system receives more data) could be improved, the issue has not yet.
We are trying to change that, work on real three-dimensional display systems on the basis of various technologies, including projections.
We need to let the computer world into our physical world and make them more tangible.
There is, however, a need that not only the users, but also recognized his surroundings.
Then we could add to the real world much easier through virtual objects.
First of all, we need these silly VR helmets los!
- What do you think about language control?
It is popular, but it is not overvalued?
- it is certainly not the solution, because it raises questions about privacy, because it would not always have all the others his actions and intentions.
In fact, any kind of interaction with computers is good, but each in their particular niche.
For example, we were working in the area of governance of objects in public places on a project in which we experimented with short and tight, with sweeping gestures.
The gestures were not from the object camera, but recorded by a bracelet, which registered the movements of the bones and muscles.
Still, it is relatively large, could theoretically be reduced to the size of a watch.
But overall, the future belongs, however, mixed management types, such gestures and language.
- How?
We would like to ask you, for example, to offer you these jets can?
You say it, and at the same time point.
Normally, I say it simply.
- Oh, that would be very difficult to detect.
- does this mean, you want the user adapt to what can make a machine at the time and what is not?
- Not necessarily, but it is a mutual rapprochement.
I think we will have to work in the next time, especially in the development of new types of sensors that allow it to capture reactions from people.
The laser sensors can be, for example, because they offer in the depths of a good resolution, which is very important.
- What claims make based on your work with the Xbox Take-sensors to modern cameras?
There is a lack of resolution, depth or something else?
The current generation is basically a good starting point for our work in the field of three-dimensional detection.
"Of course, would be at a speed of 1,000 fps not bad.
But the main thing is not the pipeline itself, but the quality of the matrix and the depth.
From this point of view, all current technologies are not good enough for us, because the developers of the algorithms have more work.
It is not only the resolution along the X and the y-, but also along the Z-axis are taken into account.
The speed and the number of frames per second are important.
The movements of people have said very dynamic and open, the current 30 fps especially for gestures are too little.
Stephen Betishes developed in our lab in Redmond, a touch sensor with an adjustable processing delay between 1 and 100 milliseconds, with today's commercial sensors are closer on the second value (60 to 100).
Not all understand how much that the interaction between man and machine.
I needed for my work as a device, only without contact control and with more frames per second.
- had to be increased the number of cameras?
- Take is currently working with three cameras, "one of them is actually an infrared transmitter, and the second a receiver for the reflected signal.
And the third camera is actually an ordinary RGB camera.
It is not used to calculate the object deep.
More cameras could solve the problem....
Or the problem, as more calculations would be necessary.
It would be a flexible, Take-like system in which we could play with different camera inclinations to determine how during the three-dimensional investigation of a position.
If I remember correctly, unlike Google, Microsoft presented his glasses, not the public.
Do you not think that the lens has regarding the application of the technology of the enlarged reality in everyday life, the best prospects?
Of course, it is not pleasant to keep logging a smartphone in the hand, but I think the following: The most amazing version would be a "changing" enhanced reality in which we could on a cloud of the glasses on the smartphone switch
The lens is a personal gadget and its strength (private) is you can only see, but also its weakness, because prevented an enlarged reality through glasses that you can work together with others in virtual objects.
- let us imagine for a moment that the manipulation of virtual holograms in the air is not only Tony Stark in Iron Man, but also ordinary mortal.
It is a problem that critics often point out this idea is that there is no tangible response.
The hands feel nothing at all.
The group wants to give the answers to this point?
- In my lectures, I often talk about the enlarged reality is the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well be the integration of the tactile perception.
An interesting method, the use of second-hand is currently as something unusual projection.
It takes pressure well.
But there are also technologies that are actually designed to give the "pictures in the air" something tangible, for example, the interference by some ultrasonic radiation directed at a certain point the finger is located, a feeling that is currently still so weak, when someone blows over the knuckles.
There are bands for the wrist that affect the nerve endings in your finger, it is also a potential direction.
- Have you tried to outflank the brain?
It can think that it can feel what it should feel if it looks just a bit?
It is a good idea, so we have tried it yet.
Here is another task with which we will have to fight for a long time, namely, a person who is physically in a closed room to believe hides, he was instead in an open, virtually infinite space; we are working on plans with treadmills (other than in gyms, movable platforms and large balls.
So far, the brain is only moderately on lists, and we still have a lot of work-years.
That makes the work in the field of virtual reality for a researcher so attractive: On many issues, we are only at the beginning.
