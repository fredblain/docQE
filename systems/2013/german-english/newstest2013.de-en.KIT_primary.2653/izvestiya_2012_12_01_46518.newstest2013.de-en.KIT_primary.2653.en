"The brain is only moderately fool"
The issue of enhanced reality, popular among supporters of modern technology is perceived in recent times, usually through the lens of a special glasses.
Google first showcased in the summer, a working model at its annual conference in November, then became aware that Microsoft had filed a patent.
In conversation with the head of the group for interactive 3D technology in Microsoft's laboratory in Cambridge Shahram Izadi, however, it is clear that the glasses for the scientists of the company was only a staging post.
It irritates the opportunity to manipulate virtual objects with their bare hands in the air and virtual space to create.
- Describe please, which conducts research for your group.
- We are concerned with the interaction between man and machine, want to extend the boundaries of this interaction.
So far, mankind has remained largely in the stage, which works with pixels on flat screens, which are sometimes affected.
However, we want to see 5-10 years ahead, and the radical changes of this interaction.
Example of the Xbox console and the Kinect sensors are a step forward, and today is no Xbox sold without Kinect, since all the interested in motion control.
- What awaits us in the future?
- Although Kinect interaction on a physical level, much is still on the flat-screen, sometimes in 3D.
The input of information (the system gets more data) could be improved, and the issue has not yet decisive.
We are trying to change the work on the basis of various technologies, including projections of real three-dimensional presentation systems.
We have to dismiss the computer world in our physical world and make it more tangible.
But it is important that not only the user but also recognizes its surroundings.
Then we could be much easier to add to the real world of virtual objects.
First and foremost, we should these silly virtual reality helmets!
- What do you think of voice control?
It is popular, but it will not be overrated?
- She is certainly not the solution which can solve all the problems, because it raises questions about privacy, because people do not want to inform all others on his actions and intentions.
Is any kind of interaction with computers, but their particular niche.
For example, we worked in the field of the management of objects in public places on a project in which we experimented with short and tight, with sprawling gestures.
The gestures were not recorded by the camera, but from a bracelet registered the movements of the bones and muscles.
It is still quite big, but it could in theory be shrunk to the size of a wristwatch.
But overall, the future is mixed control types, example, gestures and language.
- How do it?
- We would like to ask, for example, this Sprudeldose?
They say it and interpret it.
- Normally, I will say it.
- Oh, that would be very difficult to detect.
- hot, you want the user adapt to what can be a machine at the time and what is not?
- Not necessarily, but it is a mutual rapprochement.
I think that we need to work in the near future, especially in the development of new types of sensors that will enable us to collect the reactions of people.
This could be a laser sensors, for example, in the depths of a good resolution, which is very important.
- Which claims you based on your work with the Xbox Kinect sensors on modern cameras?
There is a lack of resolution, or something else?
- The current generation is basically a good starting point for our work in the field of three-dimensional.
Of course, an 8 megapixel would not be bad at a speed of 1000 fps.
But the main thing is not the Megapixel itself, but the quality of the Matrix and depth.
So all current technologies are not good enough, because the developers of the algorithms have more work for us.
It is not only the dissolution of the X and Y, but also along the Z-axis.
The speed and the number of frames per second are important.
The movements of the people are very dynamic, and frankly, the current 30 fps, particularly for gestures are not enough.
Stephen Betishes developed in our lab in Redmond a touch sensor adjustable processing delay between 1-100 milliseconds, whereas the current commercial sensors closer to the second value (60-100).
Not all understand how much influence the interaction between man and machine.
I, for my work as a device, only without the light touch controls and more frames per second.
- must not increase the number of cameras?
- Kinect is currently working with three cameras, one of them is actually an infrared transmitter, and the second is a recipient of the reflected signal.
And the third camera is actually a RGB camera.
They are not used to calculate the object.
More cameras could solve the problem...
Or the problem as more calculations.
Would be nice to have a flexible, Kinect-like system in which we could play with different camera tendencies to see how this helps us in the three-dimensional identifying a position.
- If I remember correctly, Microsoft, in contrast to Google, not his glasses to the public.
Do you not think that in terms of the application of the technology of the enlarged reality in everyday life, the lens has the best prospects?
- Of course, it is not pleasant, always on the road to a smartphone in the hand, but I think: the best option would be a "temporary" enhanced reality, we could switch on a cloud of the glasses on the smartphone,
The lens is a personal gadget, and therein lies its strength (private, you can only see), but at the same time its weakness to prevent a broader reality through glasses, you can work together with others in virtual objects.
- Imagine us for a moment that the manipulation of virtual holograms in the air, not just Tony Stark in Iron Man, but also ordinary mortal.
There is a problem that critics often point out this idea: there is no tangible response.
The hands feel nothing at all!
The answers to these objections, give your group?
- In my lectures, I often talk of the enlarged reality is the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well be the integration of the tactile perception.
An interesting method is the use of second-hand unusual projection surface.
It is perfectly true pressure!
But there are also technologies, which are designed to give the pictures in the air, something tangible, " for example, the interference of some targeted ultrasound beams at a certain point where the finger, a feeling that at the moment but there is still so weak as someone spitting on the palm.
There are also bands for the wrist on the Nervenendungen in your fingers, it is also a potential direction.
- Have you tried to outflank the brain?
We think that it can feel what it should, if it is just something?
- This is a good idea, so we have not yet been tried.
Here is another challenge, we will still have to fight a man physically located in a closed room to believe that he is, instead, in an open, virtually infinite space; we have been working on concepts with treadmills (other than in the gym), mobile platforms and large balls.
So far, the brain can only fool, and we still have many years of working.
The work in the field of virtual reality for researchers so attractive: on many issues, we are only at the beginning.
