"The brain can trick has been only moderately,"
The supporters of modern technologies popular theme of the enlarged reality is perceived lately, usually through the lens of a special glasses.
Google first presented in summer at its annual conference in November, a working model was then known that Microsoft had filed a patent.
In the interview with the head of the group for interactive 3D technologies in the Microsoft laboratory in Cambridge Shahram Izadi, however, it is clear that the glasses for the scientists of the company was only a transit station.
It irritates the opportunity to manipulate virtual objects in the air with their bare hands and to create virtual space.
- please describe what their research group operates.
- we are dealing with the interaction between man and machine, however, want to expand the borders of this interaction.
So far, the humanity is largely stuck in the phase, worked in the pixels on flat screens, which are sometimes touches.
However, we want to look 5-10 years and predict the radical changes of this interaction.
For example, the Xbox console and the new generation sensors, a step forward, and today no longer being sold without, as all interested in motion control.
- what awaits us in the future?
- even though the interaction on a physical level, much still unfolding on the flat screen, sometimes in 3D.
The input of information (the system receives more data) could be improved, the issue has not yet been decided.
We are trying to change that work on real three-dimensional display systems on the basis of various technologies, including projections.
We need to dismiss the computer world in our physical world and make fassbarer.
To do this, it is necessary, however, that it is not only the users, but also its surroundings is detected.
Then we could complement the real world much easier through virtual objects.
And we should first and foremost this bescheuerten virtual reality helmets!
What do you think about language control?
It is popular, but it is not overvalued?
- it is certainly not the all-purpose solution, because it raises questions about privacy, because it is not always like to inform all the others about his actions and intentions.
In fact any kind of interaction is good with computers, but each in their particular niche.
For example, we worked in the area of control of objects in public places on a project in which we experimented with short and tight, instead of with sweeping gestures.
The gestures were not recorded by the camera, but from a bracelet, which registered the movements of the bones and muscles.
It is a relatively large, however, in theory, could be reduced to the size of a wristwatch.
But on the whole, however, the future belongs mixed types of control, for example, gesture and language.
- like that?
- me, for example, we would ask you to them Sprudeldose?
They say it, and at the same time.
- Normally I say it simply.
- Oh, that would be very difficult to detect.
- in other words, they want that adapts to the user what can make a machine at the time and what is not?
- not necessarily, but we are talking about a mutual rapprochement.
I think that we will have to work in the near future, particularly on the development of new types that allow us to capture reactions from people in more detail.
This could be, for example, laser sensors, because they offer a good resolution in depth, which is very important.
- which claims on the basis of their work with the Xbox 360 the new generation sensors on modern cameras?
There is a lack of resolution, depth or something else?
The current generation is basically a good starting point for our work in the field of three-dimensional detection.
Of course, 8 Megapixels with a speed of 1000 fps would not be a bad thing.
But the main thing is not the Megapixel itself, but the quality of the matrix and the depth.
So all current technologies are not good enough for us, because the developers of the algorithms more work.
It must not only the resolution along the X and the Y, but also along the z-axis will be taken into account.
Also, the speed and the number of frames per second are important.
The movements of people are extremely dynamic and open said, are the current 30 fps, especially for gestures too little.
Stephen Betishes developed in our laboratory in Redmond a Ber√ºhrungssensor with an adjustable processing delay between 1 to 100 milliseconds, with today's commercial sensors are closer to the second value (60-100).
Not all understand how much the interaction between man and machine.
I needed for my work as a device, only without the touch-control and with more frames per second.
- the number of cameras should not be increased?
- is currently working with three cameras, with one of them, and the second is a recipient of the reflected signal.
And the third camera is actually an ordinary RGB camera.
They are not used to calculate the object.
Perhaps more cameras could solve the problem...
Or increase the problem, as more calculations would be necessary.
The new generation would be a flexible, similar system in which we could play with different camera inclinations, to determine how it helps us in the three-dimensional identifying a position.
- if I remember correctly, Microsoft presented to the public, in contrast to Google his glasses.
Do you not think that in terms of the application of the technology of the enlarged reality in everyday life has the best prospects?
Of course, it is not pleasant to hold a smartphone in hand, but I think the following: the best option would be a "changing" extended reality, in which we could switch on a cloud of glasses on the smartphone,
The glasses is a personal gadget, and therein lies its strength (private can only see them), but also its weakness, because an extended reality by means of glasses that they can work together with other virtual objects.
- we imagine for a moment that the virtual holograms manipulation in the air, not only from the Iron Man, but also accessible to ordinary mortals.
There is a problem, often point to the critics of this idea: there is no tangible response.
The hands feel nothing at all!
What answers your group wants to give to this objection?
- in my lectures, I often assume that the enlarged reality is the seventh breakthrough in the interaction between man and machine.
I think that the eighth breakthrough could well be the integration of tactile perception.
An interesting method is currently the use of second-hand as something unusual projection.
It performs excellently pressure.
But there are also technologies that are, in fact, to give the "pictures in the air," something tangible, for example, the interference of some ultrasonic beams at a certain point, where the finger is located, a feeling that is still so weak at the moment, however, when someone these fallen on the palm.
There are also bands for the wrist, which affect the Nervenendungen in the fingers, it is also a potential direction.
- they have tried to outflank the brain?
It is thought that it is what it should be, if it looks like something?
- it is a good idea, so we have tried it yet.
Here lies another task, with which we will have to fight for a long time, namely a man who physically located in a closed room to believe that he is instead in an open, virtually infinite space; here, we are working on concepts with treadmills (other than in gyms), movable platforms as well as large balls.
So far, the brain can outsmart only moderately, and that there are still a lot of work ahead of us rich years.
This is precisely what makes the work in the field of virtual reality for a researcher so attractive: on many issues, we are only at the beginning.
