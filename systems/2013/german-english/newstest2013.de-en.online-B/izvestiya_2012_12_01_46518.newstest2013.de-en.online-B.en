"The brain can have only moderately outsmart"
Popular with fans of modern technology theme of augmented reality is perceived lately, usually through the lens of special glasses.
Google first unveiled in the summer at its annual conference, a working model was then announced in November that Microsoft also had a corresponding patent.
In an interview with the head of the group for interactive 3D technologies in the Microsoft lab in Cambridge, Shahram Izadi, but it is clear that the glasses for the scientists of the company was only a transit station.
You intrigued by the possibility virtual objects in the air with his bare hands to manipulate and create virtual open spaces.
- Please describe briefly what your group conducts research.
- We deal with the interaction of man and machine, but it will extend the boundaries of this interaction.
So far, humanity has remained largely stuck in the phase is worked in with pixels on flat screens that are sometimes affected.
However, we want to look ahead 5-10 years and foresee the radical changes that interaction.
For example, the Xbox console and the Kinect sensors are a step forward, and now no more Xbox without Kinect is sold, as all interested in motion control.
- What else awaits us in the future?
- Even though the Kinect has brought interaction to a physical level, many things still playing on the flat screen off, sometimes in 3D.
The input of information (the system receives more data) could be improved, the issue has not yet decisive.
We're trying to change, to work on real three-dimensional display systems based on different technologies, including projections.
We need to lay off the computer world into our physical world and make them tangible.
But for this it is necessary that not only the user but also its environment is detected.
Then we could add a lot easier the real world with virtual objects.
And first of all we should be rid of this stupid virtual reality helmets!
- What do you think about voice control?
She is popular, but it is not overrated?
- It is certainly not the general purpose solution, since it raises privacy issues because you do not always inform all bystanders about its actions and intentions.
Actually, any kind of interaction is good with computers, but each in its particular niche.
For example, we worked in the field of control of objects in public places on a project where we are. Using short and concise, rather than experimenting with sweeping gestures
In this case the object is not the gesture camera, but by a bracelet have been recorded, the registered movements of the bones and muscles.
Yet it is relatively large, however, could theoretically be reduced to the size of a wrist watch.
But overall, but the future belongs to mixed control types, such as gestures and speech.
- How so?
- We would ask me, for example, you can of soda to pass this?
You say it and interpret it at the same time.
- I usually just say it.
- Oh, that would be very difficult to detect.
- Does that mean you want the user to conform to what can make a machine at the time and what not?
- Not necessarily, but it is about a rapprochement.
I think we need to be focusing their efforts on the development of new types of sensors in the near future, making it possible to capture responses from people more closely.
This can for example be laser sensors as they offer a good resolution in depth, which is very important.
- What are your requirements based on your work with the Xbox Kinect sensors in modern cameras?
Lack of resolution, depth or something else?
- The present generation is basically a good starting point for our work in the field of three-dimensional detection.
Of course, 8 megapixels would not be bad with a velocity of 1000 fps.
But the main thing is not the megapixels itself, but the quality of the matrix and the depth.
Seen in all current technologies for us is not good enough, because the developers of the algorithms have more work.
It must be taken into account not only the resolution along the X and Y, but also along the Z -axis.
Also, the speed and the number of images per second are important.
The movements of the people are told extremely dynamic and open, the current 30 fps is not enough especially for gestures.
Stephen Betishes developed in our laboratory in Redmond a touch sensor with an adjustable processing time between 1 to 100 milliseconds, the present commercial sensors are closer to the second value (60 to 100).
Not all understand how much it affects the interaction of man and machine.
For my work I needed just such a device, but without touch control and with more frames per second.
- Should the number of cameras can not be increased?
- Kinect currently uses three "cameras", one of which is actually a second infrared transmitter and a receiver for the reflected signal.
And the third camera is actually an ordinary RGB camera.
It is not used to calculate the depth of the object.
More cameras could possibly solve the problem...
Or amplify the problem, since more calculations would be necessary.
It would be nice a flexible, Kinect -like system in which we could play with different inclinations camera to determine how helps us in determining a three-dimensional position.
- If I remember correctly, Microsoft unveiled his glasses unlike Google not to the public.
Do not you think that in view of the application of the technology of augmented reality in everyday glasses have the best prospects?
- Of course it is not pleasant to go always a smart phone in his raised hand to hold, but I think the following: The greatest variation would be a "changing" augmented reality, in which we could switch through a cloud of the glasses on the smartphone,
The glasses are a personal gadget and therein lies their strength (Private, only you can see), but at the same time also its weakness, because prevents augmented reality using glasses that you can collaborate with others on virtual objects.
- Imagine for a moment that the manipulation of virtual holograms in the air is accessible not only Tony Stark from Iron Man, but also mere mortals.
There is a problem, often point to the critics of this idea: There is no tactile response!
The hands feel nothing!
What answers will give your group to this objection?
- In my lectures I speak of often that augmented reality is the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well be the integration of tactile perception.
An interesting method is currently using the second hand is somewhat unusual projection surface.
It takes pressure true outstanding!
There are also technologies that are actually designed to give the "pictures in the air" something tangible, for example, produces the interference of some directed ultrasound beams at a certain point where the finger is, a feeling but currently is still so weak, as someone blew over the palm.
There are also bands for the wrist, which act on the nerve endings in the fingers, too, is a potential direction.
- Have you tried to trick the brain?
It make you think that it feels, what it should feel when it looks just a little?
- That's a good idea, so we have not tried it yet.
Here lies a further object, with which we will have to fight for a long time, namely to allow a person who is physically located in a closed room, believing he finds it instead in an open, practically infinite space, where we are working on concepts with treadmills (other than in gyms), mobile platforms, and big balls.
So far, the brain can only moderately outwit, and before us are many busy years.
That's what makes the work in the field of virtual reality for a researcher so appealing : For many issues, we are only at the beginning.
