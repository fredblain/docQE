“The brain can be outwitted so far only moderately”
The topic of the extended reality liked with supporters of modern technologies is noticed lately usually by the lens of special eyeglasses.
Google presented first in the summer at its annual conference a functioning model, in November it became then admits that also Microsoft had announced an appropriate patent.
In the discussion with the director/conductor of the group for interactive 3D-Technologien in the Microsoft laboratory in Cambridge Shahram Izadi, it becomes however clear that the eyeglasses for the scientists of the enterprise were only one passage station.
It provokes the possibility of manipulating virtual objects in air with bare hands and of creating virtual open spaces.
- Describing you asks briefly, your group operates which research.
- We concern ourselves with the interaction of humans and machine, want to extend thereby however the borders of this interaction.
So far mankind is in the phase to a large extent puts remained, in which with pixels on flat screens one works, which are sometimes also affected.
We however want to look further ahead 5-10 years and to foresee the radical changes of this interaction.
For example the Xbox console and the Kinect sensors are a progress, and nowadays no more Xbox without Kinect one sells, since all are interested in movement control.
- Which expects us still in the future?
- Although Kinect brought the interaction on a physical level, much takes place still on the flat screen, sometimes in 3D.
The input of information (the system receives more data) could be improved, the edition so far not yet crucially.
We try to change, work on genuine three-dimensional representation systems on the basis of different technologies, under it projections.
We must dismiss the computer world into our physical world and make them more understandable.
In addition it is however necessary that not only the user, but also its environment are recognized.
Then we could supplement the real world many more simply by virtual objects.
And first of all we should become loose these crazy Virtual Reality helmets!
- Which you think of language control?
It is likes, but it is not overestimated?
- You is surely not the general-purpose solution, since it raises questions to the privacy, because one would not always like to inform all standing around about its actions and intentions.
Actually each kind of interaction with computers is well, however everyone in its certain niche.
For example we worked within the range of the control of objects on public squares on a project, with which we experimented with short and scarce, instead of with unloading gestures.
The gestures were noted not by the object camera, but by a bracelet, which registered the movements of the bones and muscles.
Still it is relatively large, could be made smaller theoretically however on the size of a wrist-watch.
But altogether the future belongs to controller types, for example gesturing however mixed and language.
- Like that?
- We would ask you me for example to hand you this mineral water box?
They say it and interpret at the same time on it.
- Normally I say it simply only.
- Oh, would be very difficult to recognize.
- Is called that, you want that the user adapts to, which can carry a machine out to the respective time and which not?
- Not necessarily, but it concerns here a mutual approach.
I think that we will work very soon particularly on the development of new sensor types to have, which make it possible to seize reactions of persons more exactly.
That for example laser sensors can be, since they offer a good dissolution in the depth, which is very important.
- Which requirements place you on the basis of your work with Xbox Kinect sensors to modern cameras?
Does it lack other one dissolution, depth or some more?
- The current generation is in the reason a good starting point for our work within the range of the three-dimensional recognition.
Naturally 8 megapixels with a speed of 1000 would not be bad fps.
But the main thing are not the megapixels themselves, but the quality of the matrix and the depth.
So seen all present technologies for us are not good enough, since the developers of the algorithms have more work.
Not only the dissolution must be considered along the x and Y, but also along the Z-axis.
Also the speed and the number of pictures per second are important.
The movements of humans are extremely dynamically and openly said, are current 30 fps in particular for gestures the too few.
Stephen Betishes developed a contact sensor with an adjustable processing delay in our laboratory in Redmond between 1 to 100 milliseconds, whereby the today's commercial sensors were more near because of the second value (60 to 100).
Not all understand, how much that affects the interaction of humans and machine.
For my work I needed exactly the same a device, only without contact control and with more pictures per second.
- Wouldn't have to be increased the number of cameras?
- Kinect works at present with three “cameras”, whereby of it an infrared transmitter and second are actually a receiver for the reflected signal.
And the third camera is actually a usual RGB camera.
It does not serve for calculation the object depth.
More cameras could possibly the problem loosen…
Or the problem strengthen, since more calculations would be necessary.
A flexible, Kinect similar system would be beautiful, with which we could play with different camera inclinations, in order to determine, how helps us with the three-dimensional determination a position.
- If I quite remember, presented Microsoft contrary to Google its eyeglasses not the public.
Don't you think that regarding the application of the technology of the extended reality in the everyday life the eyeglasses have the best prospects?
- Natural is not pleasant it to always hold on the way smartphones in the edifying hand but I think the following: The greatest variant would be a “changing” extended reality, with which we could switch over a Cloud of the eyeglasses to the smartphones,
The eyeglasses are a personal Gadget and in it lie their strength (only you), but at the same time also their weakness can see private, because an extended reality by means of eyeglasses prevents that you can work together with others on virtual objects.
- Places we us one moment long forwards that the manipulation of virtual holograms in air one did not only normal-bleach Tony Stark from Iron, but also is accessible.
There is a problem, to which critics of this idea refer frequently: There is no perceptible reaction!
The hands feel nothing at all!
Which answers does your group want to give on this objection?
- In my lectures I speak often of the fact that the extended reality represents the seventh break-through with the interaction between humans and machine.
I think, which respects break-through could quite the integration of the tactile perception become.
An interesting method is at present the use of the second hand as somewhat unusual projection document.
She notices pressure outstanding!
In addition, there are technologies, which are aligned actually to it, to lend to the “pictures in air” something strong for example produces the interference of some directed ultrasonic beams in a certain point, where the finger is, a feeling, which is momentarily however still so weak, as if blew someone over the hands.
There are also volumes for the wrist, which affect the nerve endings in the fingers, also that is a potential direction.
- Credit you tries to outwit the brain?
To think it lets that it feels, what it feel should, if it sees straight something?
- That is a good idea, then we did not try it yet.
Here a further task, with which we will have to fight still for a long time, hides itself i.e. humans, who are physically in a closed area, believes to leave, it is instead in an open, practically infinite area; here we work on concepts with run volumes (others than in fitness studios), mobile platforms as well as large balls.
So far the brain can be outwitted only moderately, and before us still many years work-filled lie.
Straight one makes the work so attractive on the area of the virtual reality for a researcher: With many topics we stand only at the beginning.
