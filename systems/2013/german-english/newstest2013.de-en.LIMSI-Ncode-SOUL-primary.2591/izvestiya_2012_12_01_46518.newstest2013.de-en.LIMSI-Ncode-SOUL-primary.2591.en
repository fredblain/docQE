"The brain can be so far only" 
The supporters of modern technology popular theme of the enlarged reality in recent times usually perceived through the lens of a special lens. 
First, Google was presented in the summer at its annual conference a working model, in November it was announced that Microsoft had filed a patent. 
In a conversation with the head of the group for interactive 3D technology in the Microsoft lab in Cambridge Shahram Izadi, but it is clear that the lens for the scientists of the company was only a staging post. 
The ability to manipulate virtual objects in the air with bare hands and to create virtual free spaces. 
- Please briefly describing what research your group. 
We are dealing with the interaction between man and machine, but we want to extend the limits of this interaction. 
So far, humanity largely stuck in the phase in which it is working with Pixeln on flat screens, which are sometimes also affected. 
We want to look ahead 5-10 years and anticipate the radical changes of this interaction. 
For example, the Xbox-Konsole and the Kinect-Sensoren are a step forward, and today is no Xbox without Kinect sold, because everyone interested in management. 
- As far as we are still expected in the future? 
- Although Kinect interaction has brought on a physical level, a lot is still on the flat screen, sometimes in 3D. 
The submission of information (the system receives more data) could be improved, the issue has not yet been decisive. 
We are trying to change the work on real three-dimensional presentation systems on the basis of various technologies, including projections. 
We have to lay off the computer world in our physical world and make them more tangible. 
To this end, it is essential that not only the user, but also its surroundings. 
Then we could make the real world much easier by adding virtual objects. 
First, we should take this crazy virtual reality wearing loose! 
- What do you think about language management? 
It is popular, but it will not be overvalued? 
- It is certainly not the Allzwecklösung, because they are issues of privacy, because they do not always all others would like to inform them about its actions and intentions. 
In fact, any kind of interaction with computers are good, but each in their particular niche. 
For example, we were working in the area of the management of objects in public places on a project in which we are short and narrow, rather than experimenting with sprawling gestures. 
In doing so, the gestures were not from the camera, but by a bracelet he always wore recorded, which observed the movements of the bones and muscles. 
It is still relatively large, in theory, however, could be reduced to the size of a Armbanduhr. 
But on the whole, however, is the future of mixed management types, such as Gestik and language. 
- How? 
- We would ask me, for example, to reach out to you this Sprudeldose? 
They say it and show at the same time. 
- Normally, I will say it simply. 
- Oh, it would be very difficult to see. 
Does this mean that you want to see the user adapt to what a machine at any given time can do and what is not? 
- Not necessarily, but we are talking here about a mutual rapprochement. 
I think that in the near future, above all, work on the development of new sensor types, which allow reactions of people to grasp. 
The laser sensors, for example, can be, because they offer a good dissolution, which is very important. 
- What are you based on your work with the Xbox Kinect-Sensoren on modern cameras? 
In the absence of dissolution, depth or anything else? 
- The current generation is basically a good starting point for our work in the area of three-dimensional detection. 
Of course, there would be 8 mega pixel with a speed of 1 000 fps is not a bad thing. 
But the main thing is not the pixel itself, but the quality of the matrix and the depth. 
In this sense, all current technologies are not good enough, because the designers of the algorithms have more work. 
It is not only along the X and Y, but also along the Z-Achse will be taken into account. 
The speed and the number of images per second are important. 
The movements of human beings are extremely dynamic and, frankly, are the present 30 fps, especially for gestures to little. 
Stephen Betishes developed a sensor in our laboratory in Redmond with a regulierbaren processing delay between 1 to 100 mm, with the current commercial carriers closer to the second value (60 to 100). 
Not everyone understands how much it affects the interaction between man and machine. 
For my work, I was just a device, only without reserve management and with more images per second. 
- If the number of cameras will not be increased? 
Kinect is currently working with three "cameras," with one of them actually an infrared station, and the second is a recipient of the reflected signal. 
And the third camera is actually an ordinary RGB-Kamera. 
It is not used to calculate the depth. 
More cameras could possibly solve the problem.... 
Or exacerbate the problem, given that more calculations would be necessary. 
It would be nice, a flexible, Kinect-ähnliches system in which we could play with different tendencies, to see how we can help in the three-dimensional identification of a position. 
- If I remember rightly, Microsoft was in contrast to Google his lens is not the public. 
Do you not think that, in terms of the application of the technology of the enlarged reality in everyday life, the lens has the best prospects? 
Of course, it is not pleasant, always en route to a smart phone in the hand, but I think the following: the tollste version would be a "rotating" enhanced reality, in which we have a cloud from the lens of the smart phone tune 
The lens is a personal 'gadget' and therein lies its strength (leaving such personal matters, you can only see), but at the same time its weakness, because it prevents an enlarged reality through glasses that you work with others in virtual objects. 
Let us imagine for a moment that the manipulation of virtual Hologramme in the air is not only Tony Stark Iron Man, but also sterblichen. 
There is a problem to which critics of this idea often: there is no noticeable reaction. 
The hands are feeling nothing at all! 
What answers to your group at this point? 
- In my lectures, I often refer to the enlarged reality the seventh breakthrough in the interaction between man and machine. 
I believe that the eighth breakthrough may well be the integration of the taktil perception. 
An interesting method is currently using the second hand as somewhat unusual instruments. 
It takes pressure very well! 
But there are also technologies, which are actually aimed at the "pictures in the air" Festival, for example, the collision produced by some rays at a certain point where the finger is a feeling at the moment but it is still so weak, as someone who pustete about appearing. 
There are also Bänder on the wrist to the Nervenendungen in the fingers, which is also a potential direction. 
- Did you try to outsmart the brain? 
I think that we can see what it should feel when it is just a little? 
- This is a good idea, so we have not yet tried it. 
This is another task with which we still have to fight for a long time, namely a person who is physically in a closed room to believe that he is instead in an open, virtually endless space; here, we are working on concepts with bands (other than spreading through gyms), mobile platforms, as well as large pellets. 
So far, we can only outsmart the brain, and we still have many busy years. 
This is precisely what makes the work in the field of virtual reality for a researcher: in many areas, we are only just beginning. 
