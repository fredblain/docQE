"The brain can be so far only moderately"
The issue of the enlarged reality is perceived by supporters of modern technologies in recent times, usually through the lens of a special glasses.
Google first presented at its annual conference in the summer, a working model in November, it was announced that Microsoft had filed a patent.
In conversation with the head of the group for interactive 3D technology in the Microsoft laboratory in Cambridge Shahram Izadi, however, it is clear that the glasses for the scientists of the company was only a staging post.
The ability to manipulate virtual objects in the air with bare hands and to create virtual open spaces.
- Please describe your, which operates research group.
- We are dealing with the interaction between man and machine, but want to extend the boundaries of this interaction.
So far, humanity is in the period, which works with pixels on flat screens, which are sometimes affected.
However, we want to look ahead 5-10 years, and the radical changes of this interaction.
For example, the Xbox console and the Kinect sensors are a step forward, and today is no Xbox sold without, because everyone interested in motion control.
- What awaits us in the future?
- Although Kinect interaction on a physical level, much is still on the flat screen, sometimes in 3D.
The input of information (the system gets more data) could be improved, the issue has not yet.
We are trying to change the work on real three-dimensional display systems based on the basis of various technologies, including projections.
We have to lay off the computer world in our physical world and make them more.
To this end, it is important that not only the user, but also its surroundings.
Then we could add to the real world much easier to virtual objects.
And the first and foremost, we should be of virtual reality helmets!
- What do you think of voice?
It is popular, but It will not be overrated?
- It is certainly not the solution, because it raises questions about privacy, because they do not like to inform all others about its actions and intentions.
In fact, any kind of interaction with computers is good, but each in their particular niche.
For example, we worked in the area of the management of objects in public places on a project in which we experimented with short and tight, with sprawling gestures.
The gestures were not recorded by the camera, but by a bracelet registered the movements of the bones and muscles.
It is still relatively large, but in theory, could be reduced to the size of a wristwatch.
But overall, the future belongs to, for example, gestures and language.
- Like that?
For example, We would ask me to reach out to you this?
They say it and, at the same time.
- Normally, I will say it.
- Oh, that would be very difficult to detect.
- That you want the user adapt to what can be a machine at the time and what is not?
- Not necessarily, but it is a mutual rapprochement.
I think that we in the near future, in particular on the development of new types of sensors, which make it possible to the people.
The laser sensors, for example, could be because they are in the depth of a good resolution, which is very important.
- What do you based on your work with the Xbox Kinect sensors on modern cameras?
There is a lack of resolution, depth or something else?
- The current generation is basically a good starting point for our work in the field of three-dimensional detection.
Of course, would not be 8 megapixels with a speed of 1000 fps.
But the main thing is not the Megapixel itself, but the quality of the matrix and depth.
So all current technologies are not good enough for us, because the developers of the algorithms have more work.
It must be taken into account not only the resolution along the X and Y, but also along the.
The speed and the number of frames per second are important.
The movements of the people are extremely dynamic and, frankly, the current 30 fps in particular for gestures too little.
Stephen Betishes in our lab in Redmond, developed a touch sensor with an adjustable processing delay between 1 to 100 milliseconds, with today's commercial sensors closer to the second value (60 to 100).
Not all understand how much it affects the interaction between man and machine.
I needed for my work as a device, only without the control and with more images per second.
- Would not be increased the number of cameras?
- Kinect is currently working with three "cameras," one of them is actually an infrared transmitter, and the second is a recipient of the reflected signal.
And the third camera is actually a RGB camera.
It is not used to calculate the object.
More cameras could possibly solve the problem.
Or the problem, as more calculations would be necessary.
It would be nice, to a flexible, system in which we could play with different camera tendencies to see how this helps us in the three-dimensional identifying a position.
- If I remember correctly, Microsoft, in contrast to Google, his glasses, not the public.
Do you not think that in terms of the application of the technology of the enlarged reality in everyday life, the lens has the best prospects?
- Of course, it is not pleasant, always on the way to keep a smartphone in your hand, but I think the following: the best option would be a "temporary" augmented reality in which we could switch on a cloud of the glasses on the smartphone,
The lens is a personal and therein lies its strength (private, you can only see), but at the same time its weakness, because an enlarged reality through glasses that you can work together with others in virtual objects.
Let us imagine for a moment that the manipulation of virtual holograms in the air, not only Tony Stark in Iron Man, but also ordinary mortal.
There is a problem that critics often point out of this idea: There is no tangible response.
The hands feel nothing at all.
What answers to give your group at this point?
- In my lectures, I often talk about the fact that the enlarged reality is the seventh breakthrough In the interaction between man and machine.
I think the eighth breakthrough could well be the integration of the tactile perception.
An interesting method is currently using the second hand as somewhat unusual projection.
It takes pressure!
But there are also technologies that are on the "pictures in the air" to give something, for example, the interference of some ultrasonic beams at a certain point where the finger, a feeling, but that is still so weak as someone on the.
There are also bands for the wrist, on the nerve endings in the fingers, it is also a potential direction.
- Have you tried to outflank the brain?
We think that it can feel what it should feel if it sees something?
- This is a good idea, so we have not tried it yet.
Here is another challenge facing us that we will have to fight for a long time, is that people who are physically in a closed room to believe,, it is instead in an open, virtually infinite space; we are working on concepts with treadmills (other than in the), mobile platforms and large balls.
So far, the brain can only moderately, and we still have many busy years of work.
It is that makes the work in the field of virtual reality for researchers so attractive: in many issues, we are only at the beginning.
