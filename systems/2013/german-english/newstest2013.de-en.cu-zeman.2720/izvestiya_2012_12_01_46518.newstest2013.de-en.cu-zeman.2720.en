“The brain is so far only moderately outsmart”
When supporters of modern technologies loves the enlarged reality in recent times, usually through the lens of a special glasses.
Google first showcased in the summer in its annual conference a working model, in November was then known, also a Microsoft patent.
In conversation with the head of the group for interactive 3d technology in Microsoft's laboratory in Cambridge, Shahram Izadi, is clear that the glasses for the scientists of the company was only a Durchgangsstation.
You are tempted by the opportunity, virtual objects in the air with their bare hands to manipulate virtual belts.
- You briefly describe what your research group.
We are dealing with the interaction of man and machine, however, want to extend the boundaries of this interaction.
So far, the humanity in the stage largely stuck in the back with Pixeln at work, sometimes.
However, we want to look ahead, 5-10 years and the radical changes of this interaction anticipate.
For example, the Xbox and the Kinect-Konsole sensors-a step forward, and today will be no more Xbox Kinect sold without, since all interested for movement.
What awaits us in the future?
Kinect-although the interaction on a physical level, plays a great deal still on the Flachbildschirm, sometimes in 3D.
The submission of information (the system receives more data) could be improved, the issue has not yet decisive.
We are trying to change, working in a real three-dimensional Darstellungssystemen on the basis of various technologies, including projections.
We need the Computerwelt in our physical world redundant and intelligible.
To this end, it is imperative that not only the user, but also its surroundings will be recognised.
We could then the real world much easier by virtual objects.
First and foremost we should these bescheuerten virtual-reality-helmets be rid of!
What do you think about Sprachsteuerung?
It is popular, but it is not overvalued?
And it is certainly not the Allzwecklösung, because it raises questions about privacy, because it is not always possible to all others about his actions and intentions would like to inform.
In fact, any sort of interaction with computers, but any good in their particular niche.
For example, we were in the area of managing properties in public places in a project for which short and tight, rather than experimenting with sprawling gestures.
The gestures were not from the Objektkamera, but by a bracelet, which recorded the movements of the bones and muscles were registered.
Still, it is relatively large, could in theory, however, about the size of a wristwatch will be reduced.
But overall the future belongs to, for example, however, mixed Steuerungstypen Gestik and language.
As this?
- We would like for example I ask you this Sprudeldose too rich?
You say it, and at the same time point.
Normally I say it simply.
Oh, that would be very difficult to see.
And this means that they want the user to adjust to what a machine at the relevant time can make and what is not?
Not necessarily, but it is a convergence.
I believe that in the near future, particularly in the development of new types of work, which will enable more accurate responses of individuals.
This could, for example, be Lasersensoren, as they are in the depths of a good offer, which is very important.
- Which claims are you based on your work with the Xbox Kinect-sensors to modern cameras?
There is a lack of depth of dissolution, or something else?
The present generation is, in fact, a good starting point for our work in the field of three-dimensional detection.
Of course, 8 Megapixel with a speed of 1,000 fps not bad.
But the main thing is not the Megapixel itself, but the quality and the depth of the matrix.
All current technologies are seen as not good enough for us, as the designer of the algorithms more work.
Not only must the dissolution of along the X-and Y-but also along the Z-axis are taken into account.
And the speed and the number of images per second are important.
The movements of the people are extremely dynamic, and to be honest, the current 30 fps especially for little gestures.
Stephen Betishes developed in our laboratory in Redmond with a Berührungssensor regulierbaren Verarbeitungsverzögerung between 1-100 milli-seconds, with today's commercial sensors closer to the second value (60 to 100).
Not everyone understands how much the interaction of man and machine.
In my work I needed just such a device, only without Berührungssteuerung and with more images per second.
The number of cameras-should not be increased?
Kinect-is currently working with three “cameras”, but one of them is actually a Infrarotsender and the second is a recipient of the reflected signal.
And the third is actually an ordinary RGB camera-camera.
It is not used to calculate the Objekttiefe.
More cameras could solve the problem …
Or the problem as more calculations would be necessary.
It would be nice to have a flexible Kinect-like system in which we could play with various Kameraneigungen in order to find out how, during the investigation of a three-dimensional position helps.
If I remember correctly, in contrast to Google, Microsoft showcased his glasses, not the public.
Do you not think that in terms of the application of the technology of the enlarged reality in the everyday life of the lens of the best prospects?
And of course it is not pleasant, always a smart phone in the collected, but I think the following: the tollste formula would be a “rotation” of enhanced reality, in which we have a cloud of the lens to the smart phone could change our tune
The lens is a personal gadget is its strength and personal matters (only you can see), but also their weakness, because a larger reality through glasses, along with others in virtual objects can work.
Let us, for a moment, that the manipulation of virtual Hologramme in the air not only Tony Stark in Iron, but rest is accessible.
There is a problem of this idea critics often point out that there are no visible reaction.
The hands felt nothing!
What answers to your group at this point?
In my classes, I often talk about the reality of the enlarged seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well be the integration of taktilen perception.
An interesting method is currently the use of second-hand as something unusual Projektionsunterlage.
It takes pressure perfectly true.
There are also technologies that actually the images “in the air” something concrete, for example, produces the collision of some Ultraschallstrahlen directed at a certain point where the finger, a feeling that, at the moment, but still so weak, as someone on the pustete Handballen.
There are bands for the Council on the nerve endings detect in the fingers of influence, which is also a potential direction.
Have you tried to outsmart the brain?
This way of thinking that it feels, what it should feel when something looks?
That is a good idea, so we have not yet tried.
Here lies another task to which we still have to struggle, that is, a man who is physically in a closed room is located, to believe that he is instead in an open, virtually infinite space; here, we are working on ideas with Laufbändern (other than in Fitnessstudios), mobile platforms and large bullets.
So far, the brain only moderately outflank and we still have many years of hard work.
This just makes the work in the field of virtual reality for a researcher appeal: on many issues we are only at the beginning.
