"The brain can trick themselves so far only modestly"
The theme popular among followers of modern technologies of augmented reality is commonly perceived in recent times through the lens of a special pair of glasses.
First, Google presented a working model in the summer at its annual Conference, in November it was announced then that Microsoft had filed a patent.
In conversation with the head of the group for interactive 3D technologies in the Microsoft lab in Cambridge Shahram Izadi, shows however that the glasses for the scientists of the company was only a transit station.
Irritating to the ability to manipulate virtual objects in the air with bare hands and to create virtual spaces.
-Describe briefly what research your group operates.
-We deal with the interaction of man and the limits of this interaction want to expand machine, however.
So far is the humanity in the phase stuck, in working with pixels on flat screens, are sometimes affected.
However, we want to 5-10 look years ahead and foresee radical changes of this interaction.
For example, the Xbox console and the Kinect sensors are a leap forward, and today no Xbox is sold without Kinect, because interested all for motion control.
-What can we expect in the future?
-Although Kinect has brought the interaction on a physical level, many things still on the flat screen takes place, sometimes in 3D.
The input information (the system gets more data) could be improved the output so far still not decisive.
We are trying to change that, working on real three-dimensional presentation systems based on different technologies, including projections.
We have released the world of computing in our physical world and make them believe.
To do this, it is but you recognize not only the user but also its surroundings.
Then, we could supplement the real world with virtual objects much easier.
And first of all we should rid this crazy one virtual-reality helmets!
-What do you think about voice control?
She is popular, but it is not overrated?
-It is certainly not the all purpose solution because it raises questions about privacy, because we would like to inform not all bystanders about his actions and intentions.
Any kind of interaction with computers is actually good, but each in its particular niche.
For example, we worked on a project where we were experimenting with short and tight, instead of using expansive gestures relating to the control of objects in public places.
While the gestures were recorded not by the object camera, but by a strap, which recorded the movements of the bone and muscles.
Still, it is relatively large, could theoretically but are shrunk to the size of a wristwatch.
But as a whole belongs to the future of however mixed control types, such as gestures and language.
-Like that?
-Would we ask me for example, to reach you with this bubble box?
You say it and pointing at the same time.
-Usually, I'll just say it.
-Oh, that would be very difficult to detect.
â€” That is, you want that the user adapts to that, what can make a machine at the relevant time and what is not?
-Not necessarily, but it involves a mutual approach.
I think that we will work in the near future mainly to the development of new sensor types, that allow to gather reactions from people.
For example laser sensors can be, because they offer a good resolution in depth, which is very important.
-Which claims do you starting from your work with the Xbox Kinect sensors in modern cameras?
Lacking resolution, depth, or anything else?
-The present generation is a good starting point for our work in the field of three-dimensional detection basically.
Of course, 8 mega pixel at a speed of 1000 would be not bad fps.
But not the mega pixels, but the quality of the matrix and the depth are the main thing.
Seen in this way, all current technologies for us are not good enough, because the developers of algorithms have more work.
It must be considered not only the resolution along the x and the y, but also along the Z axis.
The speed and the number of frames per second is important.
The movements of the people are extremely dynamic and quite frankly, too little the current 30 fps for gestures.
Stephen Betishes has developed a touch sensor with an adjustable delay of processing between 1 to 100 milliseconds, in our laboratory in Redmond where the today's commercial sensors closer to the second value (60 to 100).
Not everyone understands how much this will affect the interaction between man and machine.
For my work I needed as a device, just no touch controls and more frames per second.
-Should the number of cameras does not increase?
-Kinect is currently working with three "cameras", where one actually an infra-red transmitter and the second is a receiver for the reflected signal.
And the third camera is actually an ordinary RGB camera.
It serves not to calculate the depth of the object.
More cameras could possibly solve the problem...
Or amplify the problem because more calculations would be needed.
A flexible, Kinect-like system where we could play with different camera angles to determine how this helps us in determining three-dimensional, a position would be nice.
-If I remember correctly, Microsoft presented in contrast to Google his glasses not the public.
Don't you think that, with regard to the application of the technology of augmented reality in everyday life, the glasses has the best prospects?
-Of course, it is not pleasant to keep on the move always a Smartphone in the hand raised, but I think the following: the best variant would be a "changing" augmented reality, in which we could toggle through a cloud of spectacles on the Smartphone,
The glasses is a personal gadget and their strength lies (only you can see private), but also their weakness that prevents an augmented reality through glasses that you can work together with others on virtual objects.
-We imagine for a moment that the manipulation of virtual holograms in the air not only Tony Stark from iron is accessible to, but also mere mortals.
There is a problem that critics of this idea often point out: there is no tactile response!
The hands feel nothing at all!
The answers will your group to this objection give?
-In my lectures, I speak often of the augmented reality to represents the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well become the integration of tactile perception.
An interesting method currently is to use the second hand as a somewhat unusual projection surface.
It is excellent pressure!
There are also technologies that are actually designed to give something tangible "Images in the air", for example, the interference of some targeted ultrasound beams into a certain point where the finger is located, creates a feeling that is at the moment but still so weak, as someone on the palms of the hands blowing.
There are also tapes for the wrist, which have an effect on the nerve endings in your fingers, this is a potential direction.
-Have you tried to trick the brain?
Think it can, that it feels that what should feel it when it sees something?
-This is a good idea, so we have not tried it yet.
Here is another task that we long to fight will have, to believe someone who is physically located in a confined space, namely, he possesses virtually infinite space; instead in an open, Here we are working on concepts with treadmills (other than in gyms), moving platforms and large balls.
So far, the brain can be only moderately trick, and there are still many busy years ahead.
Just what makes the work in the field of virtual reality for a researcher so appealing: in many areas, we are only at the beginning.
