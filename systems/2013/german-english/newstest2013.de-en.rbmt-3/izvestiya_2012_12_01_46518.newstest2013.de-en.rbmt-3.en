"The brain can be outwitted up to now only moderately"
The technologies modern with followers popular subject of the enlarged reality are lately perceived for usual by the lens of special glasses.
Then first presented Google in summer with his annual conference a functioning model, in November became known that also Microsoft had announced a suitable patent.
However, in the conversation with the leader of the group for interactive 3D-technologies in the Microsoft lab in Cambridge Shahram Izadi, becomes clear that the glasses were only one stopping-off place for the scientists of the enterprise.
She irritates the possibility to manipulate virtual objects in the air with bare hands and to create virtual free surfaces.
- Describe please briefly which researches your group pursues.
- We deal with the interaction of person and machine, besides, want to extend, nevertheless, the borders of this interaction.
Up to now the humanity has got stuck mainly in the phase in which with pixels on flat panel displays is worked which are sometimes also touched.
Nevertheless, we want to look ahead 5-10 years and foresee the radical changes of this interaction.
For example, the Xbox console and the Kinect sensors are a progress, and nowadays it is sold no more Xbox without Kinect, because everybody is interested in movement control.
- What expects us still in the future?
- Although Kinect has brought the interaction on a physical level, a lot still happens on the flat panel display, sometimes in 3D.
The input of information (the system receives more data) could not be improved, the issue up to now yet decisively.
We try to change this, work on real three-dimensional representation systems on the basis of different technologies, under it projections.
We must dismiss the computer world in our physical world and make them more tangible.
However, in addition it is necessary that not only the user, but also his surroundings is recognised.
Then we could complement the real world much easier with virtual objects.
And first of all we should get rid of these goofy Virtual Reality helmets!
- What do you think about linguistic control?
It is liked, but is it not overrated?
- It is not certainly the universal solution, because it raises questions to the privacy because one would not always like to inform all bystanders about his actions and intentions.
Actually, every kind of interaction is good with computers, indeed, everybody in her certain niche.
For example, we worked in the area of the control of objects on public places on a project with which we experimented with short and scanty, instead of with very wide gestures.
Besides, the gestures were taped not by the object camera, but by a bracelet which registered the movements of the bones and muscles.
Still it is relatively big, could be reduced theoretically, nevertheless, on the size of a wristwatch.
But, however, all together the future belongs to mixed control types, for example, gesture and language.
- How this?
- We would ask you me, for example to pass to you this mineral water tin?
They say it and indicate at the same time at it.
- Ordinarily I say it just.
- Oh, this would be very difficult to recognise.
- Is this called, you want that the user adapts himself to this what can perform a machine at the respective time and what not?
-, but it is not necessarily here about a mutual approach.
I think that we must become work in the next time above all on the development of new sensor types which enable to grasp reactions of people more exactly.
These can be, for example, laser sensors, because they offer a good resolution in the depth what is very important.
- Which demands do you make outgoing from your work with the Xbox Kinect sensors to modern cameras?
Is there not enough resolution, depth or something else other?
- The current generation is basically a good starting point for our work in the area of the three-dimensional recognition.
Of course 8 Megapixel would not be bad at a speed of 1000 fps.
However, the central issue are not the mega pixels themselves, but the quality of the matrix and the depth.
Thus all present technologies are not seen for us well enough, because the developers of the algorithms have more job.
It must be considered not only the resolution along the X-and the Y-, but also along the Z axis.
Also the speed and the number of the pictures per second are important.
The movements of the person are extremely dynamic and to tell the truth, the current 30 fps are in particular for gestures not enough.
Stephen Betishes developed in our lab in Redmond a touch sensor with a regulable processing delay between from 1 to 100 milliseconds and the today's commercial sensors lie closer with the second value (from 60 to 100).
Not everybody understand, how much this influences the interaction of person and machine.
For my work I just needed a device, only without touch control and with more pictures per second.
- Would the number of the cameras not have to be raised?
- Presently Kinect works with three "cameras" and one is of it, actually, an infrared transmitter and the second one a receiver for the reflected signal.
And the third camera is really a usual RGB camera.
She does not serve for the calculation of the object depth.
More cameras could possibly solve the problem...
Or strengthen the problem, because more calculations would be necessary.
Would be nice an adaptable system Similar to Kinect with which we could play with different camera inclinations to find out how to us helps in the three-dimensional inquiry of a position.
- If I surely remember, Microsoft in contrast to Google did not present his glasses to the public.
Do you not think that in view of the use of the technology of the enlarged reality in the everyday life the glasses have the best views?
- Of course it is not pleasant to hold a Smartphone in the upraised hand on the way always, but I think follower: The most great variation would be a "varying" enlarged reality with which we could switch over about a Cloud of the glasses to the Smartphone,
The glasses are a personal Gadget and in it there lies her strength (the Private only you can see), but at the same time also her weakness, because an enlarged reality by means of glasses prevents that you can work together with other on virtual objects.
- If we imagine a moment long that the manipulation of virtual hologrammes is accessible in the air not only Tony Stark from Iron One, but also normal mortal.
There is a problem to which critics of this idea often point: There is no noticeable reaction!
The hands feel generally nothing!
Which answers wants your group on this objection to give?
- In my lectures I often speak of the fact that the enlarged reality shows the seventh breakthrough with the interaction between person and machine.
I think, the eighth breakthrough could absolutely become the integration of the tactile perception.
An interesting method is currently the use of the second hand as a little bit unusual projection base.
She perceives pressure very well!
However, there are also technologies which are aimed really to lend something sturdy to the "pictures in the air", for example, the interference of some directed ultrasonic rays generates in a certain point where the finger is, a feeling which is still so weak at the moment, however as if somebody puffed about the hand bales.
There are also tapes for the wrist which have an effect on the nervous endings in the fingers, also this is a potential direction.
- Have you tried to outwit the brain?
It allow to think that it feels this what should feel it if it sees just something?
- This is a good idea, we have not tried it yet.
Here is hidden an other job with which we will still have to fight long, namely a person who is physically in a closed space to let believe he is, instead, in an open, practically infinite space; here we work on draughts with run tapes (other than in fitness studios), movable platforms as well as big balls.
Up to now the brain can be outwitted only moderately, and before us still there lie many busy years.
Just this makes the work in the area of the virtual reality for a researcher so engaging: With many subjects we stand only at the beginning.
