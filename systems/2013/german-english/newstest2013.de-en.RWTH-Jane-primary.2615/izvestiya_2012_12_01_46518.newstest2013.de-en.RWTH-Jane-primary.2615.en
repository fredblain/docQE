"The brain is so far the only moderately"
The supporters of modern technologies purveyors of the enlarged reality is perceived in recent times, usually through the lens of a special glasses.
Google first presented at its annual conference in the summer a working model in November, was then announced that Microsoft had also filed a patent.
In conversation with the head of the group for interactive 3 D technologies in Microsoft laboratory in Cambridge Shah Ram Zhila, is clear that the glasses for the scientists of the company's only a transit station.
The to manipulate virtual objects in the air with their bare hands and to create virtual free.
- Please describe your short, which operates research group.
- We are dealing with the interaction between man and machine, but want to extend the borders of this interaction.
So far has remained largely humanity at the, which works with pixels on flat screens, which are sometimes affected.
But we want to look ahead 5-10 years, and predicted the radical changes this interaction.
For example, the Xbox console and the Kinect sensors to progress, and today is no longer sold Xbox without, because all interested.
- What awaits us in the future?
- Even the interaction on a physical level, is still much on the flat screen, sometimes in 3 D.
The input of information (the system gets more data) could not be improved, the crucial issue yet.
We are trying to change that, working on real three-dimensional display systems on the basis of various technologies, including projections.
We must dismiss the computer world in our physical world and make it more.
To this end, it is necessary not only to the user, but also its surroundings.
Then we could add to the real world much easier through virtual objects.
And first and foremost, we should be this silly virtual reality helmets!
- What do you think about language?
It is popular, but they are not overvalued?
- It is certainly not the all-purpose solution, because it raises questions about privacy, because they would like to inform all others about his actions and intentions.
In fact, any kind of interaction with computers is good, but each in their particular niche.
For example, we were working in the field of objects in public places on a project in which we are short and tight, rather than experimenting with sweeping gestures.
These were not the gestures of the object camera, but from recorded by a bracelet that the movements of the bones and muscles registered.
It is still relatively high, but in theory could be reduced to the size of a wristwatch.
But overall, however, such as the future belongs to mixed types of control, for example, gestures and language.
- Like this?
For example, we would ask you to reach out to you that Sprudeldose?
They say it and, at the same time.
Normally, I would say it.
- Oh, that would be very difficult to detect.
- That is, you want the user adjusts to what can't afford a machine at the time and what?
- Not necessarily, but it is a mutual rapprochement.
I think that we in the near future, especially in the development of new types of sensors must be working that make it possible to collect responses from people.
Can be laser sensors, for example, as they offer a good resolution, which is very important.
- What do you make claims based on your work with the Xbox, sensors on modern cameras?
There is a lack of resolution, depth or something else?
- The current generation is basically a good starting point for our work in the field of three-dimensional detection.
Of course, not 8 megapixels with a speed of 1000 fps.
But the main thing is not the Megapixel itself, but the quality of the matrix and the depth.
All current technologies are not good enough for us, the developers of the algorithms more work.
It must be taken into account not only the resolution along the X and Y, but also along the Z axis.
The speed and the number of images per second are important.
The movements of the people are extremely dynamic and open, the current 30 fps in particular for gestures too little.
Stephen Betis, developed in our laboratory in Redmond a touch sensor with an adjustable processing delay between 1 to 100 milliseconds, with today's commercial sensors closer to the second value (60 to 100).
Not all understand how much the interaction between man and machine.
I needed for my work as a device, only without the control and with more frames per second.
- The number of cameras should not be increased?
-, is currently working with three "cameras," which is one of them is actually an infrared transmitter and the second is a recipient of the reflected signal.
And the third camera is actually an ordinary RGB camera.
It is not used to calculate the object.
More cameras could solve the problem...
Or exacerbate the problem, as more calculations would be necessary.
Nice is a flexible, similar system where we could play with different camera orientation, to see how this helps us in the three-dimensional identifying a position.
- If I remember correctly, not Microsoft, Google, in contrast to his public spectacles.
Do you not think that, with regard to the application of the technology in everyday life the enlarged reality glasses of the best prospects?
- Of course, it is not pleasant always on the to keep a smartphone in your hand, but I think the following: the best option would be a "temporary" enhanced reality in which we could switch on a cloud of the glasses on the smartphone.
The lens is a personal gadget and therein lies its strength (private, you can only see), but also its weakness, because an enlarged reality by means of glasses that you can work together with others in virtual objects.
- Let us imagine for a moment that the manipulation of virtual holograms in the air only Tony Stark in Iron Man, but also ordinary mortals.
There is a problem, often point to the critics of this idea: there is no visible reaction.
The hands feel nothing at all.
What answers to give your group at this point?
- In my lectures, I often talk about the enlarged reality is the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough might well be the integration of taktilen perception.
An interesting method is the use of second hand as something unusual projection.
It takes pressure perfectly true!
But there are also technologies that are actually designed, in fact, the "pictures in the air" to give something concrete, for example, the interference by some of ultrasound beams at a certain point where the finger, a feeling that is now so weak as someone einherjar over the control.
There are also bands for the wrist on the nerve endings in the fingers, this is also a potential direction.
- Have you tried to outflank the brain?
We think that it can sense what it would feel if it sees something?
- This is a good idea, so we have not tried it yet.
Here is another challenge facing us is that we will have a long time, namely a person who is physically in a closed room, to believe that he is instead in an open, virtually infinite space, where we are working on plans with treadmills (other than in gyms), mobile platforms and large balls.
So far, the brain can outwit only moderately, and we still have many busy years.
That is what makes the work in the field of virtual reality for researchers so attractive: many issues we are at the beginning.
