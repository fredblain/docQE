"The brain is so far only moderately above list"
More recently, the popular among supporters of modern technology issue of the enlarged reality is usually seen through the lens of special glasses.
First presented a working model to Google in the summer at its annual conference in November, it was announced that Microsoft had also filed for a patent.
In conversation with the head of the group for interactive 3D technology in the Microsoft laboratory in Cambridge Shahram Izadi, it is clear, however, that the glasses for the scientists of the company was only a transit station.
It irritates the ability to manipulate virtual objects in the air with their bare hands and to create virtual space.
- please describe briefly, which conducts research your group.
- We are looking at the interaction between man and machine, however, this would expand the borders of this interaction.
So far, the human race is largely stuck in the phase of working with pixels on flat screens that can sometimes be touched.
But we want to look 5-10 years ahead and anticipate the radical changes of this interaction.
For example, the Xbox console and gamescom sensors are a step forward, and today is no longer Xbox sold without gamescom, as are all interested in motion control.
- What awaits us in the future?
- Although: The interaction has brought on a physical level is much more on the flat, sometimes in 3D.
The input of information (the system) gets more data could be improved, the issue has not decisive.
We are trying to change that, work on real 3D display systems on the basis of different technologies, including projections.
We have to fire our physical world in the computer world and make it more tangible.
To this end, it is necessary that not only the user but also its surroundings is detected.
Then we could supplement the real world much easier with virtual objects.
First and foremost, we should be happening this silly virtual reality helmets.
- What do you think about Voice?
It is popular, but it is not overvalued?
- you is certainly not the solution, because it raises questions about privacy, because it would not always inform all others about his actions and intentions.
Any kind of interaction with computers is actually good, but each in their particular niche.
For example, we worked in the area of control of objects in public places on a project in which we experimented with short and tight, instead of sprawling gestures.
The gestures were not recorded by the object camera, but by a bracelet, which registered the movements of muscles and bones.
It is still relatively high, however, theoretically could be reduced to the size of a wristwatch.
But as a whole, however, the future is mixed management types, such as language and gesture.
- How it?
We would like to ask, for example, you can in this mineral-rich?
They say it and point it at the same time.
- Normally I say it simply.
Oh, that would be very difficult to recognize.
Does that mean that you want the user to adapt to what a machine can make at the time and what is not?
- Not necessarily, but it is a mutual rapprochement.
I think that we need to be working in the near future, especially in the development of new sensor types, enabling it to capture reactions from people in more detail.
For instance, laser sensors can be, as they offer a good resolution in the deep, which is very important.
- What claims based on your work with the Xbox gamescom sensors on modern cameras?
There is a lack of resolution, depth or something else?
The current generation is basically a good starting point for our work in the field of three-dimensional detection.
Of course, a speed of 1000 fps with 8 Megapixels are not bad.
But the main thing is not the technology itself, but the quality of the matrix and the depth.
In this sense, all current technologies are not good enough for us, because the developers of the algorithms have more work.
It must be taken into account not only along the dissolution of the X-, y-, but also along the Z-axis.
The speed and the number of frames per second is also important.
The movements of people are extremely dynamic, and frankly, the current 30 fps especially for gestures are too little.
Stephen Betishes developed in our lab in Redmond a touch sensor with an adjustable processing delay from 1 to 100 milliseconds, which are closer to the modern commercial sensors on the second value (60 to 100).
Not all understand how much that affects the interaction between man and machine.
I needed for my work as a device to control only without contact with more frames per second.
- MÃ¼sste will not increase the number of cameras?
- gamescom is currently working with three "cameras, and one of them is actually an infrared transmitter, and the second is a recipient of the reflected signal.
And the third camera is actually an ordinary RGB camera.
It is not used to calculate the object depth.
More cameras could possibly solve the problem...
Or increase the problem, as more calculations would be necessary.
A flexible, gamescom-like system in which we could play with different camera inclinations would be nice to see how that helps us in a position of three-dimensional investigation.
- If I remember correctly, in contrast to Google's glasses, Microsoft is not the public.
Do you not think that, in view of the application of the technology of the enlarged reality in everyday life, the lens has the best prospects?
Of course it is not pleasant to go over to keep a smartphone in the hand, but I think the following: The neatest solution would be a "temporary" enhanced reality, in which we could switch on a cloud of the glasses on the smartphone,
The lens is its strength and is a personal gadget (private) can only see you, but also its weakness, because an extended reality through glasses prevented that you can work together with others on virtual objects.
- positions us for a moment, that not only Tony Stark in Iron Man, but also ordinary mortal accessible in the air is the manipulation of virtual holograms.
There is a problem, often point to the critics of this idea: There is no tangible response.
The hands feel nothing at all!
What answers will be your group at this point?
- In my lectures, I have often said that the enlarged reality is the seventh breakthrough in the interaction between man and machine.
I think the eighth breakthrough could well be the integration of tactile perception.
An interesting method is currently the use of second-hand as a rather unusual projection document.
It takes pressure perfectly true.
But there is also technologies that are actually designed to give something tangible to the "pictures" in the air, for example, produces the interference directed by some ultrasonic beams at a certain point, where the finger is located, a feeling that is still so weak at the moment, as these fallen someone over the knuckles.
There is also the wrist bands, the acts on his fingers in the nerve endings, this is also a potential direction.
- Do you tried to outsmart the brain?
If there is something to think that it should feel what it felt?
That is a good idea, as we have not yet tried.
Here is another challenge that we will have to fight for a long time, namely, a man who is physically located in a closed room to believe that he is instead in an open, virtually infinite space; we are working on treadmills with concepts (other than in gyms), mobile platforms, as well as large balls.
So far, the brain can be only moderately rich years through lists, and a lot of work ahead of us.
This makes the work for a researcher in the field of virtual reality so attractive: On many issues, we are just at the beginning.
