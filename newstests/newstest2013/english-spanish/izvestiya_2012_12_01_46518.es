"Por ahora, engañar al cerebro no resulta tan fácil"
El tema de la realidad aumentada, tan popular entre los aficionados a las tecnologías modernas, últimamente se percibe con normalidad principalmente a través del prisma de gafas especiales.
A inicios del verano, en su conferencia anual Google demostró un modelo en movimiento y posteriormente, en noviembre, se supo que Microsoft había presentado también una solicitud para reclamar la correspondiente patente.
Sin embargo, de una conversación con el jefe del grupo de tecnología interactiva 3D en el laboratorio de Microsoft de Cambridge, Izadi Sharamom, se dilucidó que para los científicos de dicha compañía, las gafas ya pertenecían a una etapa pasada.
A ellos les atrae la perspectiva de la manipulación de objetos virtuales en el aire con las manos desnudas y la creación de espacios virtuales abiertos.
- Por favor, en términos generales, ¿cuál es el objeto de estudio de su grupo de investigación?
- Nos dedicamos a la interacción persona-ordenador, pero además tratamos de ampliar los límites de esta interacción.
Por ahora la humanidad en su gran masa ha quedado atrapada en la etapa de trabajo con los píxeles de la pantalla plana, a veces la toca con el dedo.
Pero nosotros queremos mirar 5-10 años adelante y adivinar los cambios cardinales en esta interacción.
Por ejemplo, la consola Xbox y los sensores Kinect representan un paso adelante y hoy en día ningún Xbox se vende sin Kinect, ya que a todos les interesa el control por gestos.
- ¿Qué más nos depara el futuro?
- A pesar de que Kinect ha llevado la interacción al nivel físico, gran parte de ésta todavía ocurre en una pantalla plana, a veces en 3D.
La introducción de información ha mejorado (el sistema recibe más datos), y la salida todavía no es muy buena.
Estamos tratando de cambiar esto, trabajamos en sistemas de visualización verdaderamente tridimensionales, basados ​​en diferentes tecnologías, incluyendo las de diseño.
Se debe liberar el mundo de la informática al nuestro, al físico, hacerlo más tangible.
Para esto, sin embargo, es necesario reconocer no sólo al usuario, sino también el espacio que lo rodea.
Entonces podremos completar el mundo real con objetos virtuales de una forma más cómoda.
En primer lugar, ¡al diablo con esos tontos cascos de realidad virtual!
- ¿Qué piensa usted sobre el control por voz?
Un detalle muy popular, pero ¿no cree que lo sobreestiman?
- Claro que no se le puede considerar una panacea, queda pendiente de resolver la cuestión de privacidad, ya que no siempre se quiere que los demás se enteren de nuestras acciones e intenciones.
De hecho, todos los tipos de interacción con computadoras son buenos, pero cada uno en su propio campo.
Por ejemplo, para el control de dispositivos en lugares públicos, teníamos un proyecto en el que pensamos en los gestos, pero no en movimientos sueltos, sino más cortos.
Además, los gestos eran capturados no por la cámara del dispositivo, sino por una pulsera que registraba el movimiento de los huesos y los músculos.
Por ahora es muy grande, pero en teoría puede ser reducido al tamaño de un reloj de pulsera.
Pero, en general, el futuro es para un tipo combinado de control, por ejemplo de gesto + voz.
- ¿Cómo es eso?
- Por ejemplo, ¿cómo me pediría usted que le pasara esta lata de soda?
Usted hablará y la mostrará al mismo tiempo.
- Normalmente yo sólo hablo.
- Oh, eso va a ser muy difícil de reconocer.
- ¿O sea, usted quiere obligar a los usuarios a adaptarse a lo que puede o no puede hacer en este momento la máquina?
- No necesariamente, pero es un acercamiento mutuo.
Creo que en un futuro próximo vamos a tener que trabajar principalmente en el diseño de nuevos tipos de sensores que puedan determinar con precisión las reacciones de la persona.
Estos pueden ser, por ejemplo, sensores láser, ya que proporcionan una buena resolución en profundidad, lo que es muy importante.
- Si hablamos de su trabajo con los sensores de Xbox Kinect, ¿qué quejas tiene usted de las cámaras modernas?
¿Les falta resolución, profundidad o algo más?
- En principio, la generación actual es lo que puede ser el comienzo de nuestro trabajo con el reconocimiento tridimensional.
Por supuesto, sería bueno obtener 8 megapíxeles a la velocidad de 1000 fps.
Pero la cuestión no está en los megapíxeles, sino en la calidad de la matriz y en la profundidad.
Desde este último punto de vista, todas las tecnologías actuales no son lo suficientemente buenas para nosotros; esto da más trabajo a los diseñadores de algoritmos.
O sea, que tenemos que recordar no sólo la resolución en los ejes X e Y, sino también en Z.
También es importante la velocidad, el número de cuadros por segundo.
Los movimientos humanos son bastante dinámicos y los actuales de 30 fps son verdaderamente escasos, sobre todo para los gestos.
Steven Bathiche, de nuestro laboratorio en Redmond, hizo un sensor de contacto con retardo ajustable de procesamiento de 1 a 100 ms y cabe mencionar que los modernos sensores producidos en serie están más cerca del segundo valor (60-100).
No todo el mundo entiende en qué medida esto afecta a la interacción hombre-máquina.
A mí me sería muy útil para mi trabajo un equivalente de tal dispositivo, pero que no requiera contacto para que los cuadros por segundo sean más.
- ¿Y no es necesario aumentar el número de cámaras?
- El Kinect tiene ahora tres "cámaras", una de las cuales es de hecho el emisor de rayos infrarrojos y la segunda el receptor de la señal reflejada.
Pero la tercera cámara es en realidad un simple sensor del diapasón visible.
Ésta no se utiliza para determinar la profundidad del objeto.
Potencialmente, más cantidad de cámaras podrían resolver el problema...
O al contrario, aumentarlo y acrecentar la cantidad requerida de cálculos.
Sería bueno crear un análogo flexible de Kinect, jugar con la curvatura de ubicación de las cámaras y ver cómo esto ayudaría a determinr la posición tridimensional.
- Por lo que yo recuerdo, Microsoft, a diferencia de Google, no ha presentado sus gafas al público.
¿No le parece que, desde el punto de vista del uso diario de tecnologías de realidad aumentada, las gafas son una de las plataformas más visibles?
- Por supuesto, pasar todo el rato sosteniendo en alto un teléfono inteligente en las manos, no es muy cómodo, pero yo pienso: la mejor opción sería una realidad aumentada "transmutable" cuando, en base de una plataforma de nube, usted podría pasar de las gafas al teléfono inteligente,
Las gafas son dispositivos muy personales, en eso está su fuerza (las cosas privadas sólo usted podrá verlas), pero también su debilidad: una realidad aumentada basada en gafas no le permitirá trabajar sobre objetos virtuales junto con otras personas.
- Imaginémonos por un momento que la manipulación de objetos holográficos virtuales en el aire está disponible no sólo para Tony Stark de la película "Iron Man", sino también para cualquier simple mortal.
Hay un problema en esta idea que los críticos suelen señalar: ¡no hay respuesta táctil!
¡Las manos no sienten nada!
¿Qué respuestas prepara su grupo para este reto?
- En mis conferencias a menudo digo que la realidad aumentada es la séptima irrupción en la interacción entre el hombre y la máquina.
Creo que la octava bien podría ser la adición de sensaciones táctiles.
Mientras tanto, uno de los trucos más interesantes es el uso de la segunda mano en calidad de soporte para la imagen.
¡Registra el tacto perfectamente!
Pero existen también tecnologías que están verdaderamente orientadas a aportar tangibilidad a estas "imágenes en el aire". Por ejemplo, la interferencia de varios rayos ultrasónicos dirigidos a un punto específico donde se encuentra el dedo da una sensación similar a la que uno siente si alguien estuviera soplándole en las yemas de los dedos, pero esa sensación todavía es muy débil.
Hay también pulseras para la muñeca que influyen en las terminaciones nerviosas de los dedos, esto también una dirección prometedora.
- ¿Ha tratado de engañar al cerebro?
¿Hacerle pensar que él siente lo que parece que debería sentir en el momento en que ve algo?
- Esa es una buena idea, todavía no lo hemos intentado.
Aquí se esconde otro desafío con el que tendremos que luchar durante mucho tiempo, cómo hacer que una persona físicamente ubicada en un espacio muy reducido crea que va a un espacio abierto, casi sin fin. Estamos trabajando también en la idea de las cintas de correr (no como las de los gimnasios), plataformas móviles, así como la de los globos gigantes.
Por ahora, engañar al cerebro no resulta tan fácil, aún hay que trabajar durante muchos años.
Eso es lo que hace atractivo el trabajo con la realidad virtual para los investigadores, que muchas cosas se encuentran en un estado de total concepción.
